{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import sklearn\n",
    "import scipy\n",
    "import statsmodels\n",
    "import tensorflow\n",
    "import keras\n",
    "import theano\n",
    "import nltk\n",
    "import gensim\n",
    "import spacy\n",
    "import pydot\n",
    "import h5py\n",
    "import cv2\n",
    "import PIL\n",
    "import bokeh\n",
    "import plotly\n",
    "import cufflinks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import cv2\n",
    "import dlib\n",
    "from scipy.spatial import distance\n",
    " \n",
    "def eye_aspect_ratio(eye):\n",
    "\tA = distance.euclidean(eye[1], eye[5])\n",
    "\tB = distance.euclidean(eye[2], eye[4])\n",
    "\tC = distance.euclidean(eye[0], eye[3])\n",
    "\n",
    "\tear = (A + B) / (2.0 * C)\n",
    "\n",
    "\treturn ear\n",
    " \n",
    "thresh = 0.25\n",
    "frame_check = 20\n",
    "detect = dlib.get_frontal_face_detector()\n",
    "predict = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")# Dat file is the crux of the code\n",
    "\n",
    " \n",
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "\n",
    "  cap=cv2.VideoCapture(0) # 0 for web cam 1 for external cam \n",
    "\n",
    " flag=0 # no blink yet \n",
    "\n",
    " while True:\n",
    "\n",
    "    ret, frame=cap.read() # read the frame from camera \n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # convert to gray scale of each frames \n",
    "\n",
    "    subjects = detect(gray, 0) # detect the faces in the image \n",
    "\n",
    "    for subject in subjects: # for each detected face  \n",
    "\n",
    "        shape = predict(gray, subject)# get coordinates \n",
    "\n",
    "        shape = face_utils.shape_to_np(shape)# convert to NumPy Array\n",
    "\n",
    "        leftEye= shape[lStart:lEnd] # Landmark indices for the left eye  \n",
    "\n",
    "        rightEye= shape[rStart:rEnd]# Landmark indices for right eye  \n",
    "\n",
    "        leftEAR= eyeAspectRatio(leftEye)# calculate aspect ratio for both eyes  \n",
    "\n",
    "        rightEAR= eyeAspectRatio (rightEye)  \n",
    "\n",
    "        ear=(leftEAR+rightEAR)/2# average aspect ratio of both eyes  \n",
    "\n",
    "        left"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9480ed1053ec9e9d08afcdc22ba970ef30744498605a1ac3b09bd97451ab2d6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
